spider.activeActionPrefix = 爬取中： {0}

spider.addon.desc = Spider used for automatically finding URIs on a site.
spider.addon.name = 爬虫扩展

spider.api.action.addDomainAlwaysInScope = 使用指定的值添加始终在范围内的新域。 可选择设置新条目是否启用（默认true）以及新值是否指定为正则表达式（默认false）。
spider.api.action.addDomainAlwaysInScope.param.isEnabled = 
spider.api.action.addDomainAlwaysInScope.param.isRegex = 
spider.api.action.addDomainAlwaysInScope.param.value = 
spider.api.action.clearExcludedFromScan = 清除从爬虫扫描中排除 URL 的正则表达式。
spider.api.action.disableAllDomainsAlwaysInScope = 禁用始终在范围内的所有域。
spider.api.action.enableAllDomainsAlwaysInScope = 启用始终在范围内的所有域。
spider.api.action.excludeFromScan = 添加应从爬虫扫描中排除URL的正则表达式。
spider.api.action.excludeFromScan.param.regex = 
spider.api.action.modifyDomainAlwaysInScope = 修改始终在范围内的域。 如果启用或正则表达式，则允许修改值。 域是用它的索引来选择的，它可以通过视图 domainsAlwaysInScope 获得。
spider.api.action.modifyDomainAlwaysInScope.param.idx = 
spider.api.action.modifyDomainAlwaysInScope.param.isEnabled = 
spider.api.action.modifyDomainAlwaysInScope.param.isRegex = 
spider.api.action.modifyDomainAlwaysInScope.param.value = 
spider.api.action.pause = 
spider.api.action.pause.param.scanId = 
spider.api.action.pauseAllScans = 
spider.api.action.removeAllScans = 
spider.api.action.removeDomainAlwaysInScope = 使用给定索引删除始终在范围内的域。 可以使用视图 domainsAlwaysInScope 获取索引。
spider.api.action.removeDomainAlwaysInScope.param.idx = 
spider.api.action.removeScan = 
spider.api.action.removeScan.param.scanId = 
spider.api.action.resume = 
spider.api.action.resume.param.scanId = 
spider.api.action.resumeAllScans = 
spider.api.action.scan = Runs the spider against the given URL (or context). Optionally, the 'maxChildren' parameter can be set to limit the number of children scanned, the 'recurse' parameter can be used to prevent the spider from seeding recursively, the parameter 'contextName' can be used to constrain the scan to a Context and the parameter 'subtreeOnly' allows to restrict the spider under a site's subtree (using the specified 'url').
spider.api.action.scan.param.contextName = 
spider.api.action.scan.param.maxChildren = 
spider.api.action.scan.param.recurse = 
spider.api.action.scan.param.subtreeOnly = 
spider.api.action.scan.param.url = 
spider.api.action.scanAsUser = 从用户的角度运行Spider，用户从给定的上下文 ID 和用户 ID 获得。 有关详细信息，请参阅“扫描”操作。
spider.api.action.scanAsUser.param.contextId = 
spider.api.action.scanAsUser.param.maxChildren = 
spider.api.action.scanAsUser.param.recurse = 
spider.api.action.scanAsUser.param.subtreeOnly = 
spider.api.action.scanAsUser.param.url = 
spider.api.action.scanAsUser.param.userId = 
spider.api.action.setOptionAcceptCookies = 设置爬虫进程在爬取时是否应该接受 cookie。
spider.api.action.setOptionAcceptCookies.param.Boolean = 
spider.api.action.setOptionHandleODataParametersVisited = 
spider.api.action.setOptionHandleODataParametersVisited.param.Boolean = 
spider.api.action.setOptionHandleParameters = 
spider.api.action.setOptionHandleParameters.param.String = 
spider.api.action.setOptionMaxChildren = 设置最多可以爬取的子节点数（每节点），0表示没有限制。
spider.api.action.setOptionMaxChildren.param.Integer = 
spider.api.action.setOptionMaxDepth = 设置Spider可以爬行的最大深度，0 表示无限深度。
spider.api.action.setOptionMaxDepth.param.Integer = 
spider.api.action.setOptionMaxDuration = 
spider.api.action.setOptionMaxDuration.param.Integer = 
spider.api.action.setOptionMaxParseSizeBytes = 设置对响应必须解析的最大大小（以字节为单位）。 这允许Spider跳过大响应/文件。
spider.api.action.setOptionMaxParseSizeBytes.param.Integer = 
spider.api.action.setOptionMaxScansInUI = 
spider.api.action.setOptionMaxScansInUI.param.Integer = 
spider.api.action.setOptionParseComments = 
spider.api.action.setOptionParseComments.param.Boolean = 
spider.api.action.setOptionParseGit = 
spider.api.action.setOptionParseGit.param.Boolean = 
spider.api.action.setOptionParseRobotsTxt = 
spider.api.action.setOptionParseRobotsTxt.param.Boolean = 
spider.api.action.setOptionParseSVNEntries = 
spider.api.action.setOptionParseSVNEntries.param.Boolean = 
spider.api.action.setOptionParseSitemapXml = 
spider.api.action.setOptionParseSitemapXml.param.Boolean = 
spider.api.action.setOptionPostForm = 
spider.api.action.setOptionPostForm.param.Boolean = 
spider.api.action.setOptionProcessForm = 
spider.api.action.setOptionProcessForm.param.Boolean = 
spider.api.action.setOptionRequestWaitTime = 
spider.api.action.setOptionRequestWaitTime.param.Integer = 
spider.api.action.setOptionScopeString = Use actions [add|modify|remove]DomainAlwaysInScope instead.
spider.api.action.setOptionScopeString.param.String = 
spider.api.action.setOptionSendRefererHeader = 设置是否应在抓取时发送“Referer”标头。
spider.api.action.setOptionSendRefererHeader.param.Boolean = 
spider.api.action.setOptionShowAdvancedDialog = 
spider.api.action.setOptionShowAdvancedDialog.param.Boolean = 
spider.api.action.setOptionSkipURLString = 
spider.api.action.setOptionSkipURLString.param.String = 
spider.api.action.setOptionThreadCount = 
spider.api.action.setOptionThreadCount.param.Integer = 
spider.api.action.setOptionUserAgent = 
spider.api.action.setOptionUserAgent.param.String = 
spider.api.action.stop = 
spider.api.action.stop.param.scanId = 
spider.api.action.stopAllScans = 
spider.api.desc = 
spider.api.view.addedNodes = 返回通过指定扫描添加到站点树的节点的名称列表。
spider.api.view.addedNodes.param.scanId = 
spider.api.view.allUrls = 根据 Spider 添加的 HTTP 消息，从历史表中返回唯一 URL 列表。
spider.api.view.domainsAlwaysInScope = 获取始终在范围内的所有域。 对于每个域，显示以下内容：索引、值（域）、是否启用以及是否指定为正则表达式。
spider.api.view.excludedFromScan = 获取从Spider扫描中排除URL 的正则表达式。
spider.api.view.fullResults = 
spider.api.view.fullResults.param.scanId = 
spider.api.view.optionAcceptCookies = 获取是Spider爬虫进程在爬取时是否应该接受 cookie。
spider.api.view.optionDomainsAlwaysInScope = 请改用 domainsAlwaysInScope 视图代替
spider.api.view.optionDomainsAlwaysInScopeEnabled = 请改用 domainsAlwaysInScope 视图代替
spider.api.view.optionHandleODataParametersVisited = 
spider.api.view.optionHandleParameters = 
spider.api.view.optionMaxChildren = 获取最多可以爬取的子节点数（每节点），0表示没有限制。
spider.api.view.optionMaxDepth = 获取Spider可以爬取的最大深度，0 表示无限深度。
spider.api.view.optionMaxDuration = 
spider.api.view.optionMaxParseSizeBytes = 获取响应的必须解析的最大尺寸（以字节为单位）。
spider.api.view.optionMaxScansInUI = 
spider.api.view.optionParseComments = 
spider.api.view.optionParseGit = 
spider.api.view.optionParseRobotsTxt = 
spider.api.view.optionParseSVNEntries = 
spider.api.view.optionParseSitemapXml = 
spider.api.view.optionPostForm = 
spider.api.view.optionProcessForm = 
spider.api.view.optionRequestWaitTime = 
spider.api.view.optionScope = 
spider.api.view.optionScopeText = 
spider.api.view.optionSendRefererHeader = 获取是否应在Spider爬取时发送“Referer”标头。
spider.api.view.optionShowAdvancedDialog = 
spider.api.view.optionSkipURLString = 
spider.api.view.optionThreadCount = 
spider.api.view.optionUserAgent = 
spider.api.view.results = 
spider.api.view.results.param.scanId = 
spider.api.view.scans = 
spider.api.view.status = 
spider.api.view.status.param.scanId = 

spider.automation.desc = Spider Automation Integration
spider.automation.dialog.acceptcookies = 接受cookies
spider.automation.dialog.advanced = Show Advanced Options\:
spider.automation.dialog.context = 上下文\:
spider.automation.dialog.handleodata = Handle OData\:
spider.automation.dialog.handleparams = Handle Parameters\:
spider.automation.dialog.maxchildren = Max Children\:
spider.automation.dialog.maxdepth = Max Depth\:
spider.automation.dialog.maxduration = 最大时长：
spider.automation.dialog.maxparse = Max Size to Parse in Bytes\:
spider.automation.dialog.parsecomments = Parse Comments\:
spider.automation.dialog.parsedsstore = Parse .DS_Store\:
spider.automation.dialog.parsegit = Parse GIT\:
spider.automation.dialog.parserobots = Parse Robots.txt\:
spider.automation.dialog.parsesitemap = Parse Sitemap\:
spider.automation.dialog.parsessvn = Parse SVN\:
spider.automation.dialog.postform = Post Forms\:
spider.automation.dialog.processform = 处理表单：
spider.automation.dialog.reqwaittime = Request Wait Time
spider.automation.dialog.sendreferer = Send "Referer" Header\:
spider.automation.dialog.summary = Context\: {0}, URL\: {1}
spider.automation.dialog.tab.adv = 高级的
spider.automation.dialog.tab.parse = 解析
spider.automation.dialog.tests.stats.defaultname = At least {0} URLs found
spider.automation.dialog.threadcount = 线程数：
spider.automation.dialog.title = Spider Job
spider.automation.dialog.url = URL：
spider.automation.dialog.useragent = User Agent\:
spider.automation.error.failIfUrlsLessThan.deprecated = Job {0} the fields ''failIfFoundUrlsLessThan'' and ''warnIfFoundUrlsLessThan'' have been replaced with the {1} stats test.
spider.automation.error.nofile = 不能访问文件： {0}
spider.automation.error.url.badhost = Job {0} failed to access URL {1} check that it is valid \: {2}
spider.automation.error.url.badhost.proxychain = Job {0} failed to access URL {1} your proxy chain may be wrong \: {2}
spider.automation.error.url.failed = Job {0} failed to access URL {1} \: {2}
spider.automation.error.url.notok = Job {0} error accessing URL {1} status code returned \: {2} expected 200
spider.automation.name = Spider Automation

spider.context.popup = 爬虫上下文
spider.context.user.popup = 爬虫上下文作为用户...

spider.custom.button.reset = 重置
spider.custom.button.scan = 开始扫描
spider.custom.label.acceptcookies = 接受cookies
spider.custom.label.adv = 显示高级选项
spider.custom.label.context = 上下文\:
spider.custom.label.handleOdata = 处理 OData 参数：
spider.custom.label.maxChildren = 最多可抓取的子项（0 为无限制）：
spider.custom.label.maxDepth = 最大抓取深度（0 为无限制）：
spider.custom.label.maxDuration = 最大持续时间（分钟，0为无限制）：
spider.custom.label.maxParseSizeBytes = 最大解析大小（字节）：
spider.custom.label.parseComments = 解析 HTML 注释：
spider.custom.label.parseDsStore = Parse .DS_Store Files\:
spider.custom.label.parseGit = 解析 Git 元数据：
spider.custom.label.parseRobots = 解析 'robots.txt'\:
spider.custom.label.parseSvn = 解析 SVN 元数据：
spider.custom.label.postForms = POST 表单\:
spider.custom.label.processForms = 处理表单：
spider.custom.label.recurse = 递归\:
spider.custom.label.sendReferer = 发送“Referer”标头：
spider.custom.label.sitemap = 解析 'sitemap.xml'：
spider.custom.label.spiderSubtreeOnly = 仅爬取子树
spider.custom.label.start = 起点：
spider.custom.label.user = 用户：
spider.custom.noStartSubtreeOnly.error = 必须选择站点节点或手动引入 URL，以爬取站点的子树。
spider.custom.nostart.error = 你必须选择一个有效起点\n包括协议例如：https\://www.example.com
spider.custom.notSafe.error = 爬虫扫描不允许在“安全”模式使用
spider.custom.popup = 爬取...
spider.custom.tab.adv = 高级的
spider.custom.tab.scope = 范围
spider.custom.targetNotInScope.error = 在“受保护”模式下不允许以下目标\:\n{0}
spider.custom.title = 爬虫

spider.formhandler.desc = Spider Form Handler Integration
spider.formhandler.name = Spider Form Handler

spider.label.inScope = 抓取过程中发现的URI：
spider.label.outOfScope = 发现的URL超出抓取范围：

spider.name = 爬虫扩展

spider.options.domains.in.scope.add.button.confirm = 添加
spider.options.domains.in.scope.add.title = 添加始终在范围内的域
spider.options.domains.in.scope.dialog.remove.button.cancel = 取消
spider.options.domains.in.scope.dialog.remove.button.confirm = 删除
spider.options.domains.in.scope.dialog.remove.checkbox.label = 不要再显示此消息
spider.options.domains.in.scope.dialog.remove.text = 您确定要删除所选域吗？
spider.options.domains.in.scope.dialog.remove.title = 移除始终在范围内的域
spider.options.domains.in.scope.field.label.domain = 域：
spider.options.domains.in.scope.field.label.enabled = 启用：
spider.options.domains.in.scope.field.label.regex = 正则表达式：
spider.options.domains.in.scope.modify.button.confirm = 修改
spider.options.domains.in.scope.modify.title = 修改始终在范围内的域
spider.options.domains.in.scope.table.header.enabled = 启用
spider.options.domains.in.scope.table.header.regex = 正则表达式
spider.options.domains.in.scope.table.header.value = 域
spider.options.domains.in.scope.warning.invalid.regex.text = 正则表达式无效。
spider.options.domains.in.scope.warning.invalid.regex.title = 始终在范围内域的正则表达式无效
spider.options.irrelevantparameter.add.button.confirm = 添加
spider.options.irrelevantparameter.add.title = Add Irrelevant Parameter
spider.options.irrelevantparameter.dialog.remove.button.cancel = 取消
spider.options.irrelevantparameter.dialog.remove.button.confirm = 删除
spider.options.irrelevantparameter.dialog.remove.checkbox.label = 不要再显示此消息
spider.options.irrelevantparameter.dialog.remove.text = Are you sure you want to remove the selected parameter?
spider.options.irrelevantparameter.dialog.remove.title = Remove Irrelevant Parameter
spider.options.irrelevantparameter.field.label.enabled = 启用：
spider.options.irrelevantparameter.field.label.name = 名称\:
spider.options.irrelevantparameter.field.label.regex = 正则表达式：
spider.options.irrelevantparameter.modify.button.confirm = 修改
spider.options.irrelevantparameter.modify.title = Modify Irrelevant Parameter
spider.options.irrelevantparameter.table.header.enabled = 启用
spider.options.irrelevantparameter.table.header.regex = 正则表达式
spider.options.irrelevantparameter.table.header.value = 域
spider.options.irrelevantparameter.warning.invalid.regex.text = 正则表达式无效。
spider.options.irrelevantparameter.warning.invalid.regex.title = Irrelevant Parameter Regex Invalid
spider.options.label.acceptcookies = 接受cookies
spider.options.label.comments = 解析 HTML 注释
spider.options.label.depth = 最大抓取深度（0 为无限制）：
spider.options.label.domains = 始终在“范围内”的域
spider.options.label.dsStore = Parse .DS_Store files for new URIs
spider.options.label.duration = 最大持续时间（分钟，0为无限制）：
spider.options.label.git = 解析新 URI 的 Git 元数据文件
spider.options.label.handlehodataparameters = 处理 OData 特定的参数
spider.options.label.handleparameters = 用于检查访问的 URI 的查询参数处理：
spider.options.label.irrelevantparameters = Irrelevant parameters\:
spider.options.label.maxChildren = 最多可抓取的子项（0 为无限制）：
spider.options.label.maxParseSizeBytes = 最大解析大小（字节）：
spider.options.label.post = POST 表单（推荐但可能会产生非需要的请求）
spider.options.label.processform = 处理表单（处理表单并提交 GET 查询）
spider.options.label.robotstxt = 解析新 URI 的“robots.txt”文件
spider.options.label.sendRefererHeader = 发送“Referer”标头：
spider.options.label.sitemapxml = 解析新 URI 的“sitemap.xml”文件
spider.options.label.svnentries = 解析新 URI 的 SVN 元数据文件
spider.options.label.threads = 使用的线程数：
spider.options.title = 爬虫
spider.options.value.handleparameters.ignoreAll = 完全忽略参数
spider.options.value.handleparameters.ignoreValue = 只考虑参数的名称
spider.options.value.handleparameters.useAll = 考虑参数的名称和值

spider.panel.emptyView = 您需要先通过浏览器访问该网站，然后在显示的“站点”面板中选择一个 URL/文件夹/节点。
spider.panel.mnemonic = d
spider.panel.tab.addednodes = 已添加的节点
spider.panel.tab.messages = 消息
spider.panel.tab.urls = 网址
spider.panel.title = 爬虫

spider.parsefilter.reason.empty = 空消息
spider.parsefilter.reason.maxchildren = 最大子项
spider.parsefilter.reason.maxsize = 最大尺寸
spider.parsefilter.reason.nottext = 非文本

spider.scope.popup = 在范围内爬取全部

spider.site.popup = 爬取站点

spider.subtree.popup = 爬取子树

spider.table.flags.illegalprotocol = 非法协议
spider.table.flags.outofcontext = 超出上下文
spider.table.flags.outofscope = 超出范围
spider.table.flags.seed = 种子
spider.table.flags.userrules = 用户规则
spider.table.header.flags = 标记
spider.table.header.inScope = 已处理的
spider.table.header.method = 方法
spider.table.header.uri = URI
spider.table.messages.column.processed.successfully = 成功的
spider.table.messages.header.processed = 已处理的

spider.task.message.skipped.ioerror = I/O 错误
spider.task.message.skipped.maxdepth = 最大深度
spider.task.message.skipped.stopped = 爬虫已停止

spider.toolbar.added.label = 增加的节点：
spider.toolbar.ascans.label = 当前扫描\:
spider.toolbar.button.clear = 清除已完成的扫描
spider.toolbar.button.new = 新扫描
spider.toolbar.button.options = 爬虫选项
spider.toolbar.button.pause = 暂停爬取
spider.toolbar.button.stop = 停止爬取
spider.toolbar.button.unpause = 继续爬取
spider.toolbar.found.label = URLs未找到
spider.toolbar.progress.label = 进展：
spider.toolbar.progress.select = --选择扫描--

spider.url.popup = 爬虫URL
spider.url.user.popup = 爬虫URL作为用户...
